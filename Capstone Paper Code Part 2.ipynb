{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6d469e2c",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "280d7f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from sklearn.linear_model import LogisticRegressionCV, LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "from sklearn.decomposition import PCA \n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.decomposition import SparsePCA\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor as vif\n",
    "from sklearn.utils import resample\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "370a1277",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "path = 'robusted_merged_data.csv'\n",
    "data = pd.read_csv(path)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a04217",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the NAs in each column\n",
    "for col in data.columns:\n",
    "    count = data[col].isna().sum()\n",
    "    print(f\"{col}: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e744d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjust the content of the final rank column, and keep only two ranks\n",
    "data = data.drop(columns = ['Nan'])\n",
    "keep = ['Brigadier General', 'Major General']\n",
    "data = data[data['final rank'].isin(keep)].copy()\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b0d359",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the outcome variable and convert it to a binary.\n",
    "data['rank_code'] = data['final rank'].map({'Brigadier General': 0, 'Major General': 1})\n",
    "# Define columns of medals\n",
    "medal_columns = [c for c in data.select_dtypes(include = 'int64').columns if c not in ['name', 'final rank', 'Number of Years Served', 'average_rating', 'n_valid_ratings','rank_code']]\n",
    "# Double Check\n",
    "print(medal_columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f57f1802",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To repsect the original paper, we convert the average_rating into a cardinal order.\n",
    "data['rating'] = data['average_rating']\n",
    "data = data.drop(columns = ['rating'])\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c35008",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d6ab03",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "037e6a3d",
   "metadata": {},
   "source": [
    "### First, let's consider the accuracy of models under the normal logistic, probit, and GLM regressions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f8b809b",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors = ['rating']\n",
    "y = data['rank_code']\n",
    "X_constant = sm.add_constant(data[predictors].astype(float))\n",
    "logit = sm.Logit(y, X_constant)\n",
    "result = logit.fit(disp=False)\n",
    "\n",
    "result.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc719cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors = ['rating']\n",
    "y = data['rank_code']\n",
    "X_constant = sm.add_constant(data[predictors].astype(float))\n",
    "probit = sm.Probit(y, X_constant)\n",
    "result = probit.fit(disp=False)\n",
    "\n",
    "result.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbe47910",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-time Logit\n",
    "data['num_medals'] = data[medal_columns].sum(axis = 1)\n",
    "predictors = ['Number of Years Served', 'rating', 'num_medals']\n",
    "\n",
    "X_constant = sm.add_constant(data[predictors].astype(float))\n",
    "y = data['rank_code']\n",
    "\n",
    "logit = sm.Logit(y, X_constant)\n",
    "result = logit.fit(disp=False)\n",
    "\n",
    "result.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e5b38a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "426dfd12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-time Probit\n",
    "data['num_medals'] = data[medal_columns].sum(axis = 1)\n",
    "predictors = ['Number of Years Served', 'rating', 'num_medals']\n",
    "\n",
    "X_constant = sm.add_constant(data[predictors].astype(float))\n",
    "y = data['rank_code']\n",
    "\n",
    "probit = sm.Probit(y, X_constant)\n",
    "result = probit.fit(disp=False)\n",
    "\n",
    "result.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9af04f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's see one-time logit without rating.\n",
    "data['num_medals'] = data[medal_columns].sum(axis = 1)\n",
    "predictors = ['Number of Years Served', 'num_medals']\n",
    "\n",
    "X_constant = sm.add_constant(data[predictors].astype(float))\n",
    "y = data['rank_code']\n",
    "\n",
    "logit = sm.Logit(y, X_constant)\n",
    "result = logit.fit(disp=False)\n",
    "\n",
    "result.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9826ef1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-time Probit without rating.\n",
    "data['num_medals'] = data[medal_columns].sum(axis = 1)\n",
    "predictors = ['Number of Years Served', 'num_medals']\n",
    "\n",
    "X_constant = sm.add_constant(data[predictors].astype(float))\n",
    "y = data['rank_code']\n",
    "\n",
    "probit = sm.Probit(y, X_constant)\n",
    "result = probit.fit(disp=False)\n",
    "\n",
    "result.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67ea1b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bootstrpped Logit and its performance.\n",
    "X = data[predictors].astype(float)\n",
    "y = data['rank_code']\n",
    "\n",
    "n_bootstrap = 200\n",
    "boot_accuracies = []\n",
    "boot_coefs= []\n",
    "\n",
    "for i in range(n_bootstrap):\n",
    "    X_bs, y_bs = resample(X, y, replace=True)\n",
    "\n",
    "    # Skip if only one class is sampled (perfect class imbalance)\n",
    "    if len(np.unique(y_bs)) < 2:\n",
    "        continue\n",
    "\n",
    "    # Scale within bootstrap\n",
    "    scaler = StandardScaler()\n",
    "    X_bs_scaled = scaler.fit_transform(X_bs)\n",
    "    X_bs_scaled = sm.add_constant(X_bs_scaled)\n",
    "\n",
    "    try:\n",
    "        model = sm.Logit(y_bs, X_bs_scaled).fit(disp=False)\n",
    "        y_pred = (model.predict(X_bs_scaled) > 0.5).astype(int)\n",
    "        acc = accuracy_score(y_bs, y_pred)\n",
    "        boot_accuracies.append(acc)\n",
    "        boot_coefs.append(model.params.values)\n",
    "    except Exception as e:\n",
    "        print(f\"Iteration {i} failed: {e}\")\n",
    "        continue\n",
    "\n",
    "# Wrap results\n",
    "if len(boot_accuracies) > 0:\n",
    "    acc_summary = pd.Series(boot_accuracies).describe(percentiles=[.05, .25, .5, .75, .95])\n",
    "    coef_df = pd.DataFrame(boot_coefs, columns=['Intercept'] + predictors)\n",
    "\n",
    "    print(\"✅ Bootstrapped Accuracy Summary:\")\n",
    "    print(acc_summary)\n",
    "\n",
    "    print(\"\\n✅ Bootstrap Coefficient Means:\")\n",
    "    print(coef_df.mean())\n",
    "\n",
    "    print(\"\\n✅ Bootstrap Coefficient Std Deviations:\")\n",
    "    print(coef_df.std())\n",
    "else:\n",
    "    print(\"❌ All bootstrap iterations failed. Consider regularization or removing strong predictors.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6950bc8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bootstrpped Probit and its performance.\n",
    "X = data[predictors].astype(float)\n",
    "y = data['rank_code']\n",
    "\n",
    "n_bootstrap = 200\n",
    "boot_accuracies = []\n",
    "boot_coefs= []\n",
    "\n",
    "for i in range(n_bootstrap):\n",
    "    X_bs, y_bs = resample(X, y, replace=True)\n",
    "\n",
    "    # Skip if only one class is sampled (perfect class imbalance)\n",
    "    if len(np.unique(y_bs)) < 2:\n",
    "        continue\n",
    "\n",
    "    # Scale within bootstrap\n",
    "    scaler = StandardScaler()\n",
    "    X_bs_scaled = scaler.fit_transform(X_bs)\n",
    "    X_bs_scaled = sm.add_constant(X_bs_scaled)\n",
    "\n",
    "    try:\n",
    "        model = sm.Probit(y_bs, X_bs_scaled).fit(disp=False)\n",
    "        y_pred = (model.predict(X_bs_scaled) > 0.5).astype(int)\n",
    "        acc = accuracy_score(y_bs, y_pred)\n",
    "        boot_accuracies.append(acc)\n",
    "        boot_coefs.append(model.params.values)\n",
    "    except Exception as e:\n",
    "        print(f\"Iteration {i} failed: {e}\")\n",
    "        continue\n",
    "\n",
    "# Wrap results\n",
    "if len(boot_accuracies) > 0:\n",
    "    acc_summary = pd.Series(boot_accuracies).describe(percentiles=[.05, .25, .5, .75, .95])\n",
    "    coef_df = pd.DataFrame(boot_coefs, columns=['Intercept'] + predictors)\n",
    "\n",
    "    print(\"✅ Bootstrapped Accuracy Summary:\")\n",
    "    print(acc_summary)\n",
    "\n",
    "    print(\"\\n✅ Bootstrap Coefficient Means:\")\n",
    "    print(coef_df.mean())\n",
    "\n",
    "    print(\"\\n✅ Bootstrap Coefficient Std Deviations:\")\n",
    "    print(coef_df.std())\n",
    "else:\n",
    "    print(\"❌ All bootstrap iterations failed. Consider regularization or removing strong predictors.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c101256",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bootstrpped Logit and its performance without rating.\n",
    "X = data[predictors].astype(float)\n",
    "y = data['rank_code']\n",
    "\n",
    "n_bootstrap = 200\n",
    "boot_accuracies = []\n",
    "boot_coefs= []\n",
    "\n",
    "for i in range(n_bootstrap):\n",
    "    X_bs, y_bs = resample(X, y, replace=True)\n",
    "\n",
    "    # Skip if only one class is sampled (perfect class imbalance)\n",
    "    if len(np.unique(y_bs)) < 2:\n",
    "        continue\n",
    "\n",
    "    # Scale within bootstrap\n",
    "    scaler = StandardScaler()\n",
    "    X_bs_scaled = scaler.fit_transform(X_bs)\n",
    "    X_bs_scaled = sm.add_constant(X_bs_scaled)\n",
    "\n",
    "    try:\n",
    "        model = sm.Logit(y_bs, X_bs_scaled).fit(disp=False)\n",
    "        y_pred = (model.predict(X_bs_scaled) > 0.5).astype(int)\n",
    "        acc = accuracy_score(y_bs, y_pred)\n",
    "        boot_accuracies.append(acc)\n",
    "        boot_coefs.append(model.params.values)\n",
    "    except Exception as e:\n",
    "        print(f\"Iteration {i} failed: {e}\")\n",
    "        continue\n",
    "\n",
    "# Wrap results\n",
    "if len(boot_accuracies) > 0:\n",
    "    acc_summary = pd.Series(boot_accuracies).describe(percentiles=[.05, .25, .5, .75, .95])\n",
    "    coef_df = pd.DataFrame(boot_coefs, columns=['Intercept'] + predictors)\n",
    "\n",
    "    print(\"✅ Bootstrapped Accuracy Summary:\")\n",
    "    print(acc_summary)\n",
    "\n",
    "    print(\"\\n✅ Bootstrap Coefficient Means:\")\n",
    "    print(coef_df.mean())\n",
    "\n",
    "    print(\"\\n✅ Bootstrap Coefficient Std Deviations:\")\n",
    "    print(coef_df.std())\n",
    "else:\n",
    "    print(\"❌ All bootstrap iterations failed. Consider regularization or removing strong predictors.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "730749e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bootstrpped Probit and its performance without rating.\n",
    "X = data[predictors].astype(float)\n",
    "y = data['rank_code']\n",
    "\n",
    "n_bootstrap = 200\n",
    "boot_accuracies = []\n",
    "boot_coefs= []\n",
    "\n",
    "for i in range(n_bootstrap):\n",
    "    X_bs, y_bs = resample(X, y, replace=True)\n",
    "\n",
    "    # Skip if only one class is sampled (perfect class imbalance)\n",
    "    if len(np.unique(y_bs)) < 2:\n",
    "        continue\n",
    "\n",
    "    # Scale within bootstrap\n",
    "    scaler = StandardScaler()\n",
    "    X_bs_scaled = scaler.fit_transform(X_bs)\n",
    "    X_bs_scaled = sm.add_constant(X_bs_scaled)\n",
    "\n",
    "    try:\n",
    "        model = sm.Probit(y_bs, X_bs_scaled).fit(disp=False)\n",
    "        y_pred = (model.predict(X_bs_scaled) > 0.5).astype(int)\n",
    "        acc = accuracy_score(y_bs, y_pred)\n",
    "        boot_accuracies.append(acc)\n",
    "        boot_coefs.append(model.params.values)\n",
    "    except Exception as e:\n",
    "        print(f\"Iteration {i} failed: {e}\")\n",
    "        continue\n",
    "\n",
    "# Wrap results\n",
    "if len(boot_accuracies) > 0:\n",
    "    acc_summary = pd.Series(boot_accuracies).describe(percentiles=[.05, .25, .5, .75, .95])\n",
    "    coef_df = pd.DataFrame(boot_coefs, columns=['Intercept'] + predictors)\n",
    "\n",
    "    print(\"✅ Bootstrapped Accuracy Summary:\")\n",
    "    print(acc_summary)\n",
    "\n",
    "    print(\"\\n✅ Bootstrap Coefficient Means:\")\n",
    "    print(coef_df.mean())\n",
    "\n",
    "    print(\"\\n✅ Bootstrap Coefficient Std Deviations:\")\n",
    "    print(coef_df.std())\n",
    "else:\n",
    "    print(\"❌ All bootstrap iterations failed. Consider regularization or removing strong predictors.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fcc9828",
   "metadata": {},
   "source": [
    "### Second, let's consider the accuracy under PCA with regularized Logit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c0515cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Updated function with automatic fallback to fit_regularized() when fit() fails\n",
    "\n",
    "def run_bootstrap_pca_model_with_coefs(data, medal_columns, threshold=0.80, n_bootstrap=30, verbose=True):\n",
    "\n",
    "    # Step 1: PCA\n",
    "    X_medals = data[medal_columns].astype(float)\n",
    "    pca_full = PCA()\n",
    "    pca_full.fit(X_medals)\n",
    "    explained_var = np.cumsum(pca_full.explained_variance_ratio_)\n",
    "    n_components = np.argmax(explained_var >= threshold) + 1\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"Threshold: {threshold:.2f} → Retaining {n_components} components\")\n",
    "\n",
    "    pca = PCA(n_components=n_components)\n",
    "    X_pca = pd.DataFrame(pca.fit_transform(X_medals), columns=[f\"PC{i+1}\" for i in range(n_components)])\n",
    "\n",
    "    # Step 2: Combine with predictors\n",
    "    base_vars = ['Number of Years Served', 'rating']\n",
    "    X = pd.concat([data[base_vars].reset_index(drop=True), X_pca.reset_index(drop=True)], axis=1)\n",
    "    y = data['rank_code'].astype(int)\n",
    "    coef_names = ['const'] + base_vars + list(X_pca.columns)\n",
    "\n",
    "    # Step 3: Bootstrap logit\n",
    "    boot_accuracies = []\n",
    "    boot_coefs = []\n",
    "\n",
    "    for _ in range(n_bootstrap):\n",
    "        X_bs, y_bs = resample(X, y, replace=True)\n",
    "        if len(np.unique(y_bs)) < 2:\n",
    "            continue\n",
    "\n",
    "        scaler = StandardScaler()\n",
    "        X_bs_scaled = scaler.fit_transform(X_bs)\n",
    "        X_bs_scaled = sm.add_constant(X_bs_scaled)\n",
    "\n",
    "        try:\n",
    "            model = sm.Logit(y_bs, X_bs_scaled).fit(disp=False)\n",
    "        except:\n",
    "            try:\n",
    "                model = sm.Logit(y_bs, X_bs_scaled).fit_regularized(method='l1', alpha=0.1, disp=False)\n",
    "                if verbose:\n",
    "                    print(\"Fallback to fit_regularized() used.\")\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "        try:\n",
    "            y_pred = (model.predict(X_bs_scaled) > 0.5).astype(int)\n",
    "            acc = accuracy_score(y_bs, y_pred)\n",
    "            boot_accuracies.append(acc)\n",
    "            boot_coefs.append(model.params.values)\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "    if boot_accuracies:\n",
    "        mean_acc = np.mean(boot_accuracies)\n",
    "        std_acc = np.std(boot_accuracies)\n",
    "        coef_df = pd.DataFrame(boot_coefs, columns=coef_names)\n",
    "        if verbose:\n",
    "            print(f\"Mean Accuracy: {mean_acc:.3f}, Std: {std_acc:.3f}\")\n",
    "        return {\n",
    "            \"threshold\": threshold,\n",
    "            \"n_components\": n_components,\n",
    "            \"mean_accuracy\": mean_acc,\n",
    "            \"std_accuracy\": std_acc,\n",
    "            \"distribution\": boot_accuracies,\n",
    "            \"coef_df\": coef_df\n",
    "        }\n",
    "    else:\n",
    "        if verbose:\n",
    "            print(\"All bootstrap iterations failed.\")\n",
    "        return None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "580f7412",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Updated function without 'rating' as a predictor\n",
    "\n",
    "def run_bootstrap_pca_model_without_rating(data, medal_columns, threshold=0.80, n_bootstrap=30, verbose=True):\n",
    "    from sklearn.decomposition import PCA\n",
    "    from sklearn.utils import resample\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    import statsmodels.api as sm\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "\n",
    "    # Step 1: PCA\n",
    "    X_medals = data[medal_columns].astype(float)\n",
    "    pca_full = PCA()\n",
    "    pca_full.fit(X_medals)\n",
    "    explained_var = np.cumsum(pca_full.explained_variance_ratio_)\n",
    "    n_components = np.argmax(explained_var >= threshold) + 1\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"Threshold: {threshold:.2f} → Retaining {n_components} components\")\n",
    "\n",
    "    pca = PCA(n_components=n_components)\n",
    "    X_pca = pd.DataFrame(pca.fit_transform(X_medals), columns=[f\"PC{i+1}\" for i in range(n_components)])\n",
    "\n",
    "    # Step 2: Combine with predictors (exclude 'rating')\n",
    "    base_vars = ['Number of Years Served']\n",
    "    X = pd.concat([data[base_vars].reset_index(drop=True), X_pca.reset_index(drop=True)], axis=1)\n",
    "    y = data['rank_code'].astype(int)\n",
    "    coef_names = ['const'] + base_vars + list(X_pca.columns)\n",
    "\n",
    "    # Step 3: Bootstrap logit\n",
    "    boot_accuracies = []\n",
    "    boot_coefs = []\n",
    "\n",
    "    for _ in range(n_bootstrap):\n",
    "        X_bs, y_bs = resample(X, y, replace=True)\n",
    "        if len(np.unique(y_bs)) < 2:\n",
    "            continue\n",
    "\n",
    "        scaler = StandardScaler()\n",
    "        X_bs_scaled = scaler.fit_transform(X_bs)\n",
    "        X_bs_scaled = sm.add_constant(X_bs_scaled)\n",
    "\n",
    "        try:\n",
    "            model = sm.Logit(y_bs, X_bs_scaled).fit(disp=False)\n",
    "        except:\n",
    "            try:\n",
    "                model = sm.Logit(y_bs, X_bs_scaled).fit_regularized(method='l1', alpha=0.1, disp=False)\n",
    "                if verbose:\n",
    "                    print(\"Fallback to fit_regularized() used.\")\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "        try:\n",
    "            y_pred = (model.predict(X_bs_scaled) > 0.5).astype(int)\n",
    "            acc = accuracy_score(y_bs, y_pred)\n",
    "            boot_accuracies.append(acc)\n",
    "            boot_coefs.append(model.params.values)\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "    if boot_accuracies:\n",
    "        mean_acc = np.mean(boot_accuracies)\n",
    "        std_acc = np.std(boot_accuracies)\n",
    "        coef_df = pd.DataFrame(boot_coefs, columns=coef_names)\n",
    "        if verbose:\n",
    "            print(f\"Mean Accuracy: {mean_acc:.3f}, Std: {std_acc:.3f}\")\n",
    "        return {\n",
    "            \"threshold\": threshold,\n",
    "            \"n_components\": n_components,\n",
    "            \"mean_accuracy\": mean_acc,\n",
    "            \"std_accuracy\": std_acc,\n",
    "            \"distribution\": boot_accuracies,\n",
    "            \"coef_df\": coef_df\n",
    "        }\n",
    "    else:\n",
    "        if verbose:\n",
    "            print(\"All bootstrap iterations failed.\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02ab5b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_60 = run_bootstrap_pca_model_with_coefs(data, medal_columns, threshold=0.60)\n",
    "result_60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b956f155",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_norating60 = run_bootstrap_pca_model_without_rating(data, medal_columns, threshold=0.60, n_bootstrap=30, verbose=True)\n",
    "result_norating60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b72f1c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_70 = run_bootstrap_pca_model_with_coefs(data, medal_columns, threshold=0.70)\n",
    "result_70"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dab7bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_norating70 = run_bootstrap_pca_model_without_rating(data, medal_columns, threshold=0.70, n_bootstrap=30, verbose=True)\n",
    "result_norating70"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b798e961",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_80 = run_bootstrap_pca_model_with_coefs(data, medal_columns, threshold=0.80)\n",
    "result_80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29d271ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_norating80 = run_bootstrap_pca_model_without_rating(data, medal_columns, threshold=0.80, n_bootstrap=30, verbose=True)\n",
    "result_norating80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50638943",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_90 = run_bootstrap_pca_model_with_coefs(data, medal_columns, threshold=0.90)\n",
    "result_90"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82b9b5e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_norating90 = run_bootstrap_pca_model_without_rating(data, medal_columns, threshold=0.90, n_bootstrap=30, verbose=True)\n",
    "result_norating90"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38994311",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_95 = run_bootstrap_pca_model_with_coefs(data, medal_columns, threshold=0.95)\n",
    "result_95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fccf83c",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_norating95 = run_bootstrap_pca_model_without_rating(data, medal_columns, threshold=0.95, n_bootstrap=30, verbose=True)\n",
    "result_norating95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "049b7066",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_80[\"mean_accuracy\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f297f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_80[\"coef_df\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab421d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "coef_df = result_80[\"coef_df\"]\n",
    "\n",
    "# Mean and standard deviation\n",
    "coef_mean = coef_df.mean()\n",
    "coef_std = coef_df.std()\n",
    "\n",
    "# 95% Confidence Interval\n",
    "ci_95_lower = coef_mean - 1.96 * coef_std\n",
    "ci_95_upper = coef_mean + 1.96 * coef_std\n",
    "\n",
    "# Combine into a summary table\n",
    "coef_summary = pd.DataFrame({\n",
    "    \"Mean\": coef_mean,\n",
    "    \"Std\": coef_std,\n",
    "    \"95% CI Lower\": ci_95_lower,\n",
    "    \"95% CI Upper\": ci_95_upper\n",
    "})\n",
    "print(coef_summary.round(3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e6a00b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(coef_mean.index, coef_mean, yerr=1.96 * coef_std, capsize=4)\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.ylabel(\"Coefficient Estimate\")\n",
    "plt.title(\"Bootstrapped Coefficient Estimates (Mean ± 95% CI)\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a6a392d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.boxplot(data=coef_df, orient=\"h\")\n",
    "plt.title(\"Distribution of Bootstrapped Coefficients\")\n",
    "plt.xlabel(\"Coefficient Value\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b57d611",
   "metadata": {},
   "source": [
    "### Third, Let's consider the accuracy under Sparse PCA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6409a79c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Sparse PCA bootstrap pipeline with coefficient output\n",
    "\n",
    "def run_bootstrap_sparse_pca_model_with_coefs(data, medal_columns, n_components=5, n_bootstrap=30, alpha=1.0, verbose=True):\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"Sparse PCA → Manually set to {n_components} components | alpha = {alpha}\")\n",
    "\n",
    "    # Step 1: Sparse PCA\n",
    "    X_medals = data[medal_columns].astype(float)\n",
    "    spca = SparsePCA(n_components=n_components, alpha=alpha, random_state=42)\n",
    "    X_pca = pd.DataFrame(spca.fit_transform(X_medals), columns=[f\"SPC{i+1}\" for i in range(n_components)])\n",
    "\n",
    "    # Step 2: Combine with predictors\n",
    "    base_vars = ['Number of Years Served', 'rating']\n",
    "    X = pd.concat([data[base_vars].reset_index(drop=True), X_pca.reset_index(drop=True)], axis=1)\n",
    "    y = data['rank_code'].astype(int)\n",
    "    coef_names = ['const'] + base_vars + list(X_pca.columns)\n",
    "\n",
    "    # Step 3: Bootstrap logit\n",
    "    boot_accuracies = []\n",
    "    boot_coefs = []\n",
    "\n",
    "    for _ in range(n_bootstrap):\n",
    "        X_bs, y_bs = resample(X, y, replace=True)\n",
    "        if len(np.unique(y_bs)) < 2:\n",
    "            continue\n",
    "\n",
    "        scaler = StandardScaler()\n",
    "        X_bs_scaled = scaler.fit_transform(X_bs)\n",
    "        X_bs_scaled = sm.add_constant(X_bs_scaled)\n",
    "\n",
    "        try:\n",
    "            model = sm.Logit(y_bs, X_bs_scaled).fit(disp=False)\n",
    "        except:\n",
    "            try:\n",
    "                model = sm.Logit(y_bs, X_bs_scaled).fit_regularized(method='l1', alpha=0.1, disp=False)\n",
    "                if verbose:\n",
    "                    print(\"Fallback to fit_regularized() used.\")\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "        try:\n",
    "            y_pred = (model.predict(X_bs_scaled) > 0.5).astype(int)\n",
    "            acc = accuracy_score(y_bs, y_pred)\n",
    "            boot_accuracies.append(acc)\n",
    "            boot_coefs.append(model.params.values)\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "    if boot_accuracies:\n",
    "        mean_acc = np.mean(boot_accuracies)\n",
    "        std_acc = np.std(boot_accuracies)\n",
    "        coef_df = pd.DataFrame(boot_coefs, columns=coef_names)\n",
    "        if verbose:\n",
    "            print(f\"Mean Accuracy: {mean_acc:.3f}, Std: {std_acc:.3f}\")\n",
    "        return {\n",
    "            \"n_components\": n_components,\n",
    "            \"mean_accuracy\": mean_acc,\n",
    "            \"std_accuracy\": std_acc,\n",
    "            \"distribution\": boot_accuracies,\n",
    "            \"coef_df\": coef_df\n",
    "        }\n",
    "    else:\n",
    "        if verbose:\n",
    "            print(\"All bootstrap iterations failed.\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c451e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modified version of Sparse PCA bootstrap function that excludes \"rating\"\n",
    "\n",
    "def run_bootstrap_sparse_pca_model_without_rating(data, medal_columns, n_components=5, n_bootstrap=30, alpha=1.0, verbose=True):\n",
    "    from sklearn.decomposition import SparsePCA\n",
    "    from sklearn.utils import resample\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    import statsmodels.api as sm\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"Sparse PCA → Manually set to {n_components} components | alpha = {alpha}\")\n",
    "\n",
    "    # Step 1: Sparse PCA\n",
    "    X_medals = data[medal_columns].astype(float)\n",
    "    spca = SparsePCA(n_components=n_components, alpha=alpha, random_state=42)\n",
    "    X_pca = pd.DataFrame(spca.fit_transform(X_medals), columns=[f\"SPC{i+1}\" for i in range(n_components)])\n",
    "\n",
    "    # Step 2: Combine with predictors (exclude 'rating')\n",
    "    base_vars = ['Number of Years Served']\n",
    "    X = pd.concat([data[base_vars].reset_index(drop=True), X_pca.reset_index(drop=True)], axis=1)\n",
    "    y = data['rank_code'].astype(int)\n",
    "    coef_names = ['const'] + base_vars + list(X_pca.columns)\n",
    "\n",
    "    # Step 3: Bootstrap logit\n",
    "    boot_accuracies = []\n",
    "    boot_coefs = []\n",
    "\n",
    "    for _ in range(n_bootstrap):\n",
    "        X_bs, y_bs = resample(X, y, replace=True)\n",
    "        if len(np.unique(y_bs)) < 2:\n",
    "            continue\n",
    "\n",
    "        scaler = StandardScaler()\n",
    "        X_bs_scaled = scaler.fit_transform(X_bs)\n",
    "        X_bs_scaled = sm.add_constant(X_bs_scaled)\n",
    "\n",
    "        try:\n",
    "            model = sm.Logit(y_bs, X_bs_scaled).fit(disp=False)\n",
    "        except:\n",
    "            try:\n",
    "                model = sm.Logit(y_bs, X_bs_scaled).fit_regularized(method='l1', alpha=0.1, disp=False)\n",
    "                if verbose:\n",
    "                    print(\"Fallback to fit_regularized() used.\")\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "        try:\n",
    "            y_pred = (model.predict(X_bs_scaled) > 0.5).astype(int)\n",
    "            acc = accuracy_score(y_bs, y_pred)\n",
    "            boot_accuracies.append(acc)\n",
    "            boot_coefs.append(model.params.values)\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "    if boot_accuracies:\n",
    "        mean_acc = np.mean(boot_accuracies)\n",
    "        std_acc = np.std(boot_accuracies)\n",
    "        coef_df = pd.DataFrame(boot_coefs, columns=coef_names)\n",
    "        if verbose:\n",
    "            print(f\"Mean Accuracy: {mean_acc:.3f}, Std: {std_acc:.3f}\")\n",
    "        return {\n",
    "            \"n_components\": n_components,\n",
    "            \"mean_accuracy\": mean_acc,\n",
    "            \"std_accuracy\": std_acc,\n",
    "            \"distribution\": boot_accuracies,\n",
    "            \"coef_df\": coef_df\n",
    "        }\n",
    "    else:\n",
    "        if verbose:\n",
    "            print(\"All bootstrap iterations failed.\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac229ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_sparse5 = run_bootstrap_sparse_pca_model_with_coefs(\n",
    "    data, \n",
    "    medal_columns, \n",
    "    n_components=5,   \n",
    "    alpha=1.0,        \n",
    "    n_bootstrap=30\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37408dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_spca_no_rating5 = run_bootstrap_sparse_pca_model_without_rating(\n",
    "    data, \n",
    "    medal_columns, \n",
    "    n_components=5, \n",
    "    n_bootstrap=30, \n",
    "    alpha=1.0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a242aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "result_sparse6 = run_bootstrap_sparse_pca_model_with_coefs(\n",
    "    data, \n",
    "    medal_columns, \n",
    "    n_components=6,   \n",
    "    alpha=1.0,        \n",
    "    n_bootstrap=30\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82856e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_spca_no_rating6 = run_bootstrap_sparse_pca_model_without_rating(\n",
    "    data, \n",
    "    medal_columns, \n",
    "    n_components=6, \n",
    "    n_bootstrap=30, \n",
    "    alpha=1.0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a2a59d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_sparse7 = run_bootstrap_sparse_pca_model_with_coefs(\n",
    "    data, \n",
    "    medal_columns, \n",
    "    n_components=7,   \n",
    "    alpha=1.0,        \n",
    "    n_bootstrap=30\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3038db3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_spca_no_rating7 = run_bootstrap_sparse_pca_model_without_rating(\n",
    "    data, \n",
    "    medal_columns, \n",
    "    n_components=7, \n",
    "    n_bootstrap=30, \n",
    "    alpha=1.0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f31fa6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_sparse8 = run_bootstrap_sparse_pca_model_with_coefs(\n",
    "    data, \n",
    "    medal_columns, \n",
    "    n_components=8,   \n",
    "    alpha=1.0,        \n",
    "    n_bootstrap=30\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7de04064",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_spca_no_rating8 = run_bootstrap_sparse_pca_model_without_rating(\n",
    "    data, \n",
    "    medal_columns, \n",
    "    n_components=8, \n",
    "    n_bootstrap=30, \n",
    "    alpha=1.0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c28889",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_sparse9 = run_bootstrap_sparse_pca_model_with_coefs(\n",
    "    data, \n",
    "    medal_columns, \n",
    "    n_components=9,   \n",
    "    alpha=1.0,        \n",
    "    n_bootstrap=30\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca0e136c",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_spca_no_rating9 = run_bootstrap_sparse_pca_model_without_rating(\n",
    "    data, \n",
    "    medal_columns, \n",
    "    n_components=9, \n",
    "    n_bootstrap=30, \n",
    "    alpha=1.0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa00bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_sparse10 = run_bootstrap_sparse_pca_model_with_coefs(\n",
    "    data, \n",
    "    medal_columns, \n",
    "    n_components=10,   \n",
    "    alpha=1.0,        \n",
    "    n_bootstrap=30\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60f4f7a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_spca_no_rating10 = run_bootstrap_sparse_pca_model_without_rating(\n",
    "    data, \n",
    "    medal_columns, \n",
    "    n_components=10, \n",
    "    n_bootstrap=30, \n",
    "    alpha=1.0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f73c1e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_sparse11 = run_bootstrap_sparse_pca_model_with_coefs(\n",
    "    data, \n",
    "    medal_columns, \n",
    "    n_components=11,   \n",
    "    alpha=1.0,        \n",
    "    n_bootstrap=30\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b50f56a",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_spca_no_rating11 = run_bootstrap_sparse_pca_model_without_rating(\n",
    "    data, \n",
    "    medal_columns, \n",
    "    n_components=11, \n",
    "    n_bootstrap=30, \n",
    "    alpha=1.0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56802d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_sparse12 = run_bootstrap_sparse_pca_model_with_coefs(\n",
    "    data, \n",
    "    medal_columns, \n",
    "    n_components=12,   \n",
    "    alpha=1.0,        \n",
    "    n_bootstrap=30\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd2245a",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_spca_no_rating12 = run_bootstrap_sparse_pca_model_without_rating(\n",
    "    data, \n",
    "    medal_columns, \n",
    "    n_components=12, \n",
    "    n_bootstrap=30, \n",
    "    alpha=1.0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3af41aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "coef_df = result_sparse10[\"coef_df\"]\n",
    "summary = pd.DataFrame({\n",
    "    \"Mean\": coef_df.mean(),\n",
    "    \"Std\": coef_df.std(),\n",
    "    \"95% CI Lower\": coef_df.mean() - 1.96 * coef_df.std(),\n",
    "    \"95% CI Upper\": coef_df.mean() + 1.96 * coef_df.std()\n",
    "})\n",
    "print(summary.round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec26e9c",
   "metadata": {},
   "source": [
    "### Fourth, let's consider the Manually Grouping Logistic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f9df1e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define medal tiers\n",
    "tier1 = [\n",
    "    'Medal of Honor', 'Distinguished Service Cross', 'Navy Cross', 'Silver Star', 'Bronze Star'\n",
    "]\n",
    "\n",
    "tier2 = [\n",
    "    'Distinguished Service Medal', 'Legion of Merit', 'Purple Heart', 'Oak Leaf Cluster',\n",
    "    'Public Welfare Medal'\n",
    "]\n",
    "\n",
    "tier3 = [\n",
    "    'Civil War Campaign Medal', 'Indian Campaign Medal', 'Mexican Border Service Medal',\n",
    "    'Philippine Campaign Medal', 'Philippine Congressional Medal',\n",
    "    'Cuban Pacification Medal', 'Spanish Campaign Medal', 'Spanish War Service Medal',\n",
    "    'World War I Victory Medal', 'War Merit Cross', \n",
    "]\n",
    "\n",
    "tier4 = [\n",
    "    'Companion Of The Order Of The Bath (United Kingdom)', 'Croix de Guerre',\n",
    "    'Czechoslovak War Cross 1918', 'French Legion Of Honor (Commander)',\n",
    "    'Grand Cordon of the Order of the Sacred Treasure', 'Honorary Knight Commande',\n",
    "    'Legion of Honor', 'Order Of Leopold Ii (Belgium)', 'Order Of The Black Star (Commander)',\n",
    "    'Order of La Solidaridad (Panama)', 'Order of Leopold', 'Order of Saints Maurice and Lazarus',\n",
    "    'Order of St Michael and St George', 'Order of Wen Hu', 'Order of the Bath',\n",
    "    'Order of the Crown', 'Order of the Dragon of Annam', 'Order of the Rising Sun',\n",
    "    'Order of the Star of Africa'\n",
    "]\n",
    "\n",
    "# Fill NaNs with 0 to avoid issues with summing\n",
    "data[tier1 + tier2 + tier3 + tier4] = data[tier1 + tier2 + tier3 + tier4].fillna(0)\n",
    "\n",
    "# Create new columns for medal tier counts\n",
    "data['num_medal_tier1'] = data[tier1].sum(axis=1)\n",
    "data['num_medal_tier2'] = data[tier2].sum(axis=1)\n",
    "data['num_medal_tier3'] = data[tier3].sum(axis=1)\n",
    "data['num_medal_tier4'] = data[tier4].sum(axis=1)\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cf90b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "num1 = data['num_medal_tier1'].sum()\n",
    "num2 = data['num_medal_tier2'].sum()\n",
    "num3 = data['num_medal_tier3'].sum()\n",
    "num4 = data['num_medal_tier4'].sum()\n",
    "print(num1,num2,num3,num4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ff2783",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors = ['Number of Years Served', 'rating', 'num_medal_tier1','num_medal_tier2','num_medal_tier3','num_medal_tier4']\n",
    "\n",
    "X_constant = sm.add_constant(data[predictors].astype(float))\n",
    "y = data['rank_code']\n",
    "\n",
    "model = sm.Logit(y,X_constant).fit_regularized(method = 'l1', alpha=1.0)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb144cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = sm.Probit(y,X_constant).fit_regularized(method = 'l1', alpha = 1.0)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df1bd67f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a bootstrap function for custom predictors including medal tiers and rating\n",
    "\n",
    "def run_bootstrap_custom_logit_model(data, predictors, n_bootstrap=30, verbose=True):\n",
    "    from sklearn.utils import resample\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    import statsmodels.api as sm\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "\n",
    "    X = data[predictors].astype(float).reset_index(drop=True)\n",
    "    y = data['rank_code'].astype(int).reset_index(drop=True)\n",
    "    coef_names = ['const'] + predictors\n",
    "\n",
    "    boot_accuracies = []\n",
    "    boot_coefs = []\n",
    "\n",
    "    for _ in range(n_bootstrap):\n",
    "        X_bs, y_bs = resample(X, y, replace=True)\n",
    "        if len(np.unique(y_bs)) < 2:\n",
    "            continue\n",
    "\n",
    "        scaler = StandardScaler()\n",
    "        X_bs_scaled = scaler.fit_transform(X_bs)\n",
    "        X_bs_scaled = sm.add_constant(X_bs_scaled)\n",
    "\n",
    "        try:\n",
    "            model = sm.Logit(y_bs, X_bs_scaled).fit(disp=False)\n",
    "        except:\n",
    "            try:\n",
    "                model = sm.Logit(y_bs, X_bs_scaled).fit_regularized(method='l1', alpha=0.5, disp=False)\n",
    "                if verbose:\n",
    "                    print(\"Fallback to fit_regularized() used.\")\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "        try:\n",
    "            y_pred = (model.predict(X_bs_scaled) > 0.5).astype(int)\n",
    "            acc = accuracy_score(y_bs, y_pred)\n",
    "            boot_accuracies.append(acc)\n",
    "            boot_coefs.append(model.params.values)\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "    if boot_accuracies:\n",
    "        mean_acc = np.mean(boot_accuracies)\n",
    "        std_acc = np.std(boot_accuracies)\n",
    "        coef_df = pd.DataFrame(boot_coefs, columns=coef_names)\n",
    "        if verbose:\n",
    "            print(f\"Mean Accuracy: {mean_acc:.3f}, Std: {std_acc:.3f}\")\n",
    "        return {\n",
    "            \"mean_accuracy\": mean_acc,\n",
    "            \"std_accuracy\": std_acc,\n",
    "            \"distribution\": boot_accuracies,\n",
    "            \"coef_df\": coef_df\n",
    "        }\n",
    "    else:\n",
    "        if verbose:\n",
    "            print(\"All bootstrap iterations failed.\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee527bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors = [\n",
    "    'Number of Years Served', \n",
    "    'rating', \n",
    "    'num_medal_tier1',\n",
    "    'num_medal_tier2',\n",
    "    'num_medal_tier3',\n",
    "    'num_medal_tier4'\n",
    "]\n",
    "\n",
    "result_custom = run_bootstrap_custom_logit_model(data, predictors, n_bootstrap=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7d08820",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors = [\n",
    "    'Number of Years Served', \n",
    "    'num_medal_tier1',\n",
    "    'num_medal_tier2',\n",
    "    'num_medal_tier3',\n",
    "    'num_medal_tier4'\n",
    "]\n",
    "\n",
    "result_custom = run_bootstrap_custom_logit_model(data, predictors, n_bootstrap=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d50b8181",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_custom[\"mean_accuracy\"]\n",
    "\n",
    "result_custom[\"coef_df\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b6de68",
   "metadata": {},
   "outputs": [],
   "source": [
    "coef_df =result_custom[\"coef_df\"].mean()\n",
    "coef_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15f97851",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Simulated usage: result_custom[\"coef_df\"] exists from previous bootstrap\n",
    "# Here we assume result_custom is already defined in the user's session\n",
    "coef_df = result_custom[\"coef_df\"]\n",
    "\n",
    "# Calculate summary statistics\n",
    "coef_mean = coef_df.mean()\n",
    "coef_std = coef_df.std()\n",
    "ci_95_lower = coef_mean - 1.96 * coef_std\n",
    "ci_95_upper = coef_mean + 1.96 * coef_std\n",
    "\n",
    "# Combine into summary table\n",
    "coef_summary = pd.DataFrame({\n",
    "    \"Mean\": coef_mean,\n",
    "    \"Std\": coef_std,\n",
    "    \"95% CI Lower\": ci_95_lower,\n",
    "    \"95% CI Upper\": ci_95_upper\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e21b83b",
   "metadata": {},
   "outputs": [],
   "source": [
    "coef_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02371eb0",
   "metadata": {},
   "source": [
    "### Fifth, let's consider manually grouping based PCA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea63efb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the bootstrapped grouped PCA function for both cases (with/without rating)\n",
    "\n",
    "def run_grouped_pca_bootstrap(\n",
    "    data,\n",
    "    medal_groups,\n",
    "    group_n_components,\n",
    "    n_bootstrap=30,\n",
    "    include_rating=True,\n",
    "    verbose=True\n",
    "):\n",
    "    from sklearn.decomposition import PCA\n",
    "    from sklearn.utils import resample\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    import statsmodels.api as sm\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "\n",
    "    pcs_all = []\n",
    "\n",
    "    # Step 1: Run PCA for each group and store results\n",
    "    for group_name, medals in medal_groups.items():\n",
    "        n_comp = group_n_components.get(group_name, 1)\n",
    "        X_group = data[medals].astype(float).fillna(0)\n",
    "\n",
    "        if X_group.shape[1] == 0 or X_group.var().sum() == 0:\n",
    "            continue\n",
    "\n",
    "        pca = PCA(n_components=n_comp)\n",
    "        group_pcs = pca.fit_transform(X_group)\n",
    "        pcs_df = pd.DataFrame(group_pcs, columns=[f\"{group_name}_PC{i+1}\" for i in range(n_comp)])\n",
    "        pcs_all.append(pcs_df)\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"{group_name}: {n_comp} component(s) retained\")\n",
    "\n",
    "    # Step 2: Combine all PCs\n",
    "    all_pcs = pd.concat(pcs_all, axis=1)\n",
    "\n",
    "    # Step 3: Add other predictors\n",
    "    base_vars = ['Number of Years Served']\n",
    "    if include_rating:\n",
    "        base_vars.append('rating')\n",
    "\n",
    "    X = pd.concat([data[base_vars].reset_index(drop=True), all_pcs.reset_index(drop=True)], axis=1)\n",
    "    y = data['rank_code'].astype(int).reset_index(drop=True)\n",
    "    coef_names = ['const'] + base_vars + list(all_pcs.columns)\n",
    "\n",
    "    # Step 4: Bootstrap logit\n",
    "    boot_accuracies = []\n",
    "    boot_coefs = []\n",
    "\n",
    "    for _ in range(n_bootstrap):\n",
    "        X_bs, y_bs = resample(X, y, replace=True)\n",
    "        if len(np.unique(y_bs)) < 2:\n",
    "            continue\n",
    "\n",
    "        scaler = StandardScaler()\n",
    "        X_bs_scaled = scaler.fit_transform(X_bs)\n",
    "        X_bs_scaled = sm.add_constant(X_bs_scaled)\n",
    "\n",
    "        try:\n",
    "            model = sm.Logit(y_bs, X_bs_scaled).fit(disp=False)\n",
    "        except:\n",
    "            try:\n",
    "                model = sm.Logit(y_bs, X_bs_scaled).fit_regularized(method='l1', alpha=0.1, disp=False)\n",
    "                if verbose:\n",
    "                    print(\"Fallback to fit_regularized() used.\")\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "        try:\n",
    "            y_pred = (model.predict(X_bs_scaled) > 0.5).astype(int)\n",
    "            acc = accuracy_score(y_bs, y_pred)\n",
    "            boot_accuracies.append(acc)\n",
    "            boot_coefs.append(model.params.values)\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "    if boot_accuracies:\n",
    "        mean_acc = np.mean(boot_accuracies)\n",
    "        std_acc = np.std(boot_accuracies)\n",
    "        coef_df = pd.DataFrame(boot_coefs, columns=coef_names)\n",
    "        if verbose:\n",
    "            print(f\"Mean Accuracy: {mean_acc:.3f}, Std: {std_acc:.3f}\")\n",
    "        return {\n",
    "            \"mean_accuracy\": mean_acc,\n",
    "            \"std_accuracy\": std_acc,\n",
    "            \"distribution\": boot_accuracies,\n",
    "            \"coef_df\": coef_df\n",
    "        }\n",
    "    else:\n",
    "        if verbose:\n",
    "            print(\"All bootstrap iterations failed.\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6809980c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tier1 = [\n",
    "    'Medal of Honor', 'Distinguished Service Cross', 'Navy Cross', 'Silver Star', 'Bronze Star'\n",
    "]\n",
    "\n",
    "tier2 = [\n",
    "    'Distinguished Service Medal', 'Legion of Merit', 'Purple Heart', 'Oak Leaf Cluster',\n",
    "    'Public Welfare Medal'\n",
    "]\n",
    "\n",
    "tier3 = [\n",
    "    'Civil War Campaign Medal', 'Indian Campaign Medal', 'Mexican Border Service Medal',\n",
    "    'Philippine Campaign Medal', 'Philippine Congressional Medal',\n",
    "    'Cuban Pacification Medal', 'Spanish Campaign Medal', 'Spanish War Service Medal',\n",
    "    'World War I Victory Medal', 'War Merit Cross', \n",
    "]\n",
    "\n",
    "tier4 = [\n",
    "    'Companion Of The Order Of The Bath (United Kingdom)', 'Croix de Guerre',\n",
    "    'Czechoslovak War Cross 1918', 'French Legion Of Honor (Commander)',\n",
    "    'Grand Cordon of the Order of the Sacred Treasure', 'Honorary Knight Commande',\n",
    "    'Legion of Honor', 'Order Of Leopold Ii (Belgium)', 'Order Of The Black Star (Commander)',\n",
    "    'Order of La Solidaridad (Panama)', 'Order of Leopold', 'Order of Saints Maurice and Lazarus',\n",
    "    'Order of St Michael and St George', 'Order of Wen Hu', 'Order of the Bath',\n",
    "    'Order of the Crown', 'Order of the Dragon of Annam', 'Order of the Rising Sun',\n",
    "    'Order of the Star of Africa'\n",
    "]\n",
    "\n",
    "medal_groups = {\n",
    "    \"tier1\": tier1,\n",
    "    \"tier2\": tier2,\n",
    "    \"tier3\": tier3,\n",
    "    \"tier4\": tier4\n",
    "}\n",
    "\n",
    "group_n_components = {\n",
    "    \"tier1\": 1,\n",
    "    \"tier2\": 1,\n",
    "    \"tier3\": 1,\n",
    "    \"tier4\": 1\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a211d531",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_grouped_with_rating = run_grouped_pca_bootstrap(\n",
    "    data, medal_groups, group_n_components, include_rating=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69417868",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_grouped_no_rating = run_grouped_pca_bootstrap(\n",
    "    data, medal_groups, group_n_components, include_rating=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57d4c6ed",
   "metadata": {},
   "source": [
    "### Sixth, now let's try bootstrap based KRR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d999ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-import required modules after code state reset\n",
    "def run_bootstrap_krr_model(data, predictors, target_col='rank_code', n_bootstrap=30, alpha=1.0, kernel='rbf', gamma=None, verbose=True):\n",
    "    from sklearn.kernel_ridge import KernelRidge\n",
    "    from sklearn.utils import resample\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "\n",
    "    X = data[predictors].astype(float).reset_index(drop=True)\n",
    "    y = data[target_col].astype(int).reset_index(drop=True)\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "    boot_accuracies = []\n",
    "    coef_like_storage = []\n",
    "\n",
    "    for _ in range(n_bootstrap):\n",
    "        X_bs, y_bs = resample(X_scaled, y, replace=True)\n",
    "        if len(np.unique(y_bs)) < 2:\n",
    "            continue\n",
    "\n",
    "        model = KernelRidge(alpha=alpha, kernel=kernel, gamma=gamma)\n",
    "        model.fit(X_bs, y_bs)\n",
    "\n",
    "        y_pred_continuous = model.predict(X_bs)\n",
    "        y_pred_binary = (y_pred_continuous > 0.5).astype(int)\n",
    "        acc = accuracy_score(y_bs, y_pred_binary)\n",
    "        boot_accuracies.append(acc)\n",
    "\n",
    "        # For linear kernel, store \"coef-like\" from dual + X\n",
    "        if kernel == 'linear':\n",
    "            coef_like = X_bs.T @ model.dual_coef_\n",
    "            coef_like_storage.append(coef_like)\n",
    "\n",
    "    result = {\n",
    "        \"mean_accuracy\": np.mean(boot_accuracies),\n",
    "        \"std_accuracy\": np.std(boot_accuracies),\n",
    "        \"distribution\": boot_accuracies,\n",
    "    }\n",
    "\n",
    "    if kernel == 'linear' and coef_like_storage:\n",
    "        result[\"coef_df\"] = pd.DataFrame(coef_like_storage, columns=predictors)\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"Mean Accuracy: {result['mean_accuracy']:.3f}, Std: {result['std_accuracy']:.3f}\")\n",
    "\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06c67937",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors = ['Number of Years Served', 'rating', 'num_medal_tier1', 'num_medal_tier2', 'num_medal_tier3', 'num_medal_tier4']\n",
    "\n",
    "result_krr = run_bootstrap_krr_model(\n",
    "    data,\n",
    "    predictors=predictors,\n",
    "    target_col='rank_code',   # where 0 = Brigadier General, 1 = Major General\n",
    "    n_bootstrap=30,\n",
    "    alpha=1.0,\n",
    "    kernel='rbf',             # or 'linear' if you want interpretable weights\n",
    "    gamma=0.5                 # optional for RBF\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2030461b",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors = ['Number of Years Served', 'num_medal_tier1', 'num_medal_tier2', 'num_medal_tier3', 'num_medal_tier4']\n",
    "\n",
    "result_krr = run_bootstrap_krr_model(\n",
    "    data,\n",
    "    predictors=predictors,\n",
    "    target_col='rank_code',   # where 0 = Brigadier General, 1 = Major General\n",
    "    n_bootstrap=30,\n",
    "    alpha=1.0,\n",
    "    kernel='rbf',             # or 'linear' if you want interpretable weights\n",
    "    gamma=0.5                 # optional for RBF\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1169754",
   "metadata": {},
   "outputs": [],
   "source": [
    "medal_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf1fc19",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_predictors = ['Number of Years Served', 'rating'] + medal_columns\n",
    "\n",
    "# Run the model\n",
    "result_krr_full = run_bootstrap_krr_model(\n",
    "    data=data,\n",
    "    predictors=full_predictors,\n",
    "    target_col='rank_code',\n",
    "    n_bootstrap=30,\n",
    "    alpha=1.0,\n",
    "    kernel='rbf',\n",
    "    gamma=0.5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "421e2523",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_predictors = ['Number of Years Served'] + medal_columns\n",
    "\n",
    "# Run the model\n",
    "result_krr_full = run_bootstrap_krr_model(\n",
    "    data=data,\n",
    "    predictors=full_predictors,\n",
    "    target_col='rank_code',\n",
    "    n_bootstrap=30,\n",
    "    alpha=1.0,\n",
    "    kernel='rbf',\n",
    "    gamma=0.5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54fbbd65",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_predictors = ['Number of Years Served', 'rating'] + medal_columns\n",
    "\n",
    "# Run the model\n",
    "result_krr_full_linear = run_bootstrap_krr_model(\n",
    "    data=data,\n",
    "    predictors=full_predictors,\n",
    "    target_col='rank_code',\n",
    "    n_bootstrap=30,\n",
    "    alpha=1.0,\n",
    "    kernel='linear',\n",
    "    gamma=0.5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd5c6aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_krr_full_linear['coef_df']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ba75ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_predictors = ['Number of Years Served'] + medal_columns\n",
    "\n",
    "# Run the model\n",
    "result_krr_full_linear = run_bootstrap_krr_model(\n",
    "    data=data,\n",
    "    predictors=full_predictors,\n",
    "    target_col='rank_code',\n",
    "    n_bootstrap=30,\n",
    "    alpha=1.0,\n",
    "    kernel='linear',\n",
    "    gamma=0.5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "380ffa91",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_krr_full_linear['coef_df']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a3cdcf0",
   "metadata": {},
   "source": [
    "### Seventh, now let's consider Random Forest ands XGBoosting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05421730",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.utils import resample\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Define bootstrap function for Random Forest\n",
    "def run_bootstrap_random_forest_model(data, predictors, target_col='rank_code', n_bootstrap=30, n_estimators=100, max_depth=None, verbose=True):\n",
    "    X = data[predictors].astype(float).reset_index(drop=True)\n",
    "    y = data[target_col].astype(int).reset_index(drop=True)\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "    boot_accuracies = []\n",
    "    feature_importances = []\n",
    "\n",
    "    for _ in range(n_bootstrap):\n",
    "        X_bs, y_bs = resample(X_scaled, y, replace=True)\n",
    "        if len(np.unique(y_bs)) < 2:\n",
    "            continue\n",
    "\n",
    "        model = RandomForestClassifier(\n",
    "            n_estimators=n_estimators,\n",
    "            max_depth=max_depth,\n",
    "            random_state=42,\n",
    "            n_jobs=-1\n",
    "        )\n",
    "        model.fit(X_bs, y_bs)\n",
    "\n",
    "        y_pred = model.predict(X_bs)\n",
    "        acc = accuracy_score(y_bs, y_pred)\n",
    "        boot_accuracies.append(acc)\n",
    "        feature_importances.append(model.feature_importances_)\n",
    "\n",
    "    result = {\n",
    "        \"mean_accuracy\": np.mean(boot_accuracies),\n",
    "        \"std_accuracy\": np.std(boot_accuracies),\n",
    "        \"distribution\": boot_accuracies,\n",
    "        \"feature_importances_df\": pd.DataFrame(feature_importances, columns=predictors)\n",
    "    }\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"Mean Accuracy: {result['mean_accuracy']:.3f}, Std: {result['std_accuracy']:.3f}\")\n",
    "\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d4b739",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_predictors = ['Number of Years Served', 'rating'] + medal_columns\n",
    "result_rf = run_bootstrap_random_forest_model(\n",
    "    data=data,\n",
    "    predictors=full_predictors,\n",
    "    n_bootstrap=10,         # reduce from 30 to 10\n",
    "    n_estimators=50,        # reduce forest size\n",
    "    max_depth=5,            # cap tree depth\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04ea78ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_predictors = ['Number of Years Served'] + medal_columns\n",
    "result_rf_norating = run_bootstrap_random_forest_model(\n",
    "    data=data,\n",
    "    predictors=full_predictors,\n",
    "    n_bootstrap=10,         # reduce from 30 to 10\n",
    "    n_estimators=50,        # reduce forest size\n",
    "    max_depth=5,            # cap tree depth\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "264dce37",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Define bootstrap function for XGBoost\n",
    "def run_bootstrap_xgboost_model(data, predictors, target_col='rank_code', n_bootstrap=30, max_depth=3, learning_rate=0.1, n_estimators=100, verbose=True):\n",
    "    from sklearn.utils import resample\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "\n",
    "    X = data[predictors].astype(float).reset_index(drop=True)\n",
    "    y = data[target_col].astype(int).reset_index(drop=True)\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "    boot_accuracies = []\n",
    "    feature_importances = []\n",
    "\n",
    "    for _ in range(n_bootstrap):\n",
    "        X_bs, y_bs = resample(X_scaled, y, replace=True)\n",
    "        if len(np.unique(y_bs)) < 2:\n",
    "            continue\n",
    "\n",
    "        model = XGBClassifier(\n",
    "            n_estimators=n_estimators,\n",
    "            max_depth=max_depth,\n",
    "            learning_rate=learning_rate,\n",
    "            use_label_encoder=False,\n",
    "            eval_metric='logloss',\n",
    "            verbosity=0\n",
    "        )\n",
    "        model.fit(X_bs, y_bs)\n",
    "\n",
    "        y_pred = model.predict(X_bs)\n",
    "        acc = accuracy_score(y_bs, y_pred)\n",
    "        boot_accuracies.append(acc)\n",
    "        feature_importances.append(model.feature_importances_)\n",
    "\n",
    "    result = {\n",
    "        \"mean_accuracy\": np.mean(boot_accuracies),\n",
    "        \"std_accuracy\": np.std(boot_accuracies),\n",
    "        \"distribution\": boot_accuracies,\n",
    "        \"feature_importances_df\": pd.DataFrame(feature_importances, columns=predictors)\n",
    "    }\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"Mean Accuracy: {result['mean_accuracy']:.3f}, Std: {result['std_accuracy']:.3f}\")\n",
    "\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d88231a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_predictors = ['Number of Years Served', 'rating'] + medal_columns\n",
    "result = run_bootstrap_xgboost_model(\n",
    "    data=data,\n",
    "    predictors=full_predictors,\n",
    "target_col='rank_code', n_bootstrap=30, max_depth=3, learning_rate=0.1, n_estimators=100, verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a73cf5a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_predictors = ['Number of Years Served'] + medal_columns\n",
    "result_norating = run_bootstrap_xgboost_model(\n",
    "    data=data,\n",
    "    predictors=full_predictors,\n",
    "target_col='rank_code', n_bootstrap=30, max_depth=3, learning_rate=0.1, n_estimators=100, verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "773197d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.inspection import PartialDependenceDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 1. Prepare the full dataset\n",
    "X_full = data[full_predictors].astype(float).reset_index(drop=True)\n",
    "y_full = data['rank_code'].astype(int).reset_index(drop=True)\n",
    "\n",
    "# 2. Scale features\n",
    "scaler = StandardScaler()\n",
    "X_scaled_full = scaler.fit_transform(X_full)\n",
    "\n",
    "# 3. Fit a single XGBoost model on full data\n",
    "model_full = XGBClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=3,\n",
    "    learning_rate=0.1,\n",
    "    use_label_encoder=False,\n",
    "    eval_metric='logloss',\n",
    "    verbosity=0\n",
    ")\n",
    "model_full.fit(X_scaled_full, y_full)\n",
    "\n",
    "# 4. Plot PDP for the 'rating' feature\n",
    "# Get the index of 'rating' in full_predictors list\n",
    "rating_index = full_predictors.index('rating')\n",
    "\n",
    "# Plot partial dependence\n",
    "display = PartialDependenceDisplay.from_estimator(\n",
    "    model_full,\n",
    "    X_scaled_full,\n",
    "    features=[rating_index],\n",
    "    feature_names=full_predictors,\n",
    "    kind=\"average\",\n",
    "    grid_resolution=100\n",
    ")\n",
    "\n",
    "plt.title(\"Partial Dependence of 'rating' on Promotion Probability\")\n",
    "plt.tight_layout()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "368d0cd1",
   "metadata": {},
   "source": [
    "### Eighth, now let's try the idea from the paper: Causal Inference with Corrupted Data: Measurement Error, Missing Values, Discretization, and Differential Privacy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a0ffb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from sklearn.linear_model import LogisticRegressionCV, LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "from sklearn.decomposition import PCA\n",
    "from matplotlib import pyplot as plt \n",
    "from sklearn.decomposition import SparsePCA\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor as vif \n",
    "from sklearn.utils import resample\n",
    "from sklearn.metrics import accuracy_score\n",
    "from fancyimpute import SoftImpute\n",
    "from econml.dml import DML\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61bdadf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(medal_columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e9028d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_bin = data[medal_columns].replace(0, np.nan).astype(float)\n",
    "X_latent = SoftImpute(max_rank = 5).fit_transform(X_bin.values)\n",
    "\n",
    "pca = PCA(n_components=5)\n",
    "X_latent_5 = pca.fit_transform(X_latent)  # Now shape is (170, 5)\n",
    "\n",
    "data_latent = pd.DataFrame(X_latent_5, columns = [f'latent_medal_{i+1}' for i in range(X_latent_5.shape[1])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0939d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_latent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f7b6b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_combined = pd.concat([data_latent, data[['rank_code', 'rating', 'Number of Years Served']].reset_index(drop=True)], axis = 1)\n",
    "data_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcec0c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine covariates\n",
    "X_covariates = np.column_stack([X_latent_5, data['Number of Years Served']])\n",
    "T = data['rating'].values\n",
    "Y = data['rank_code'].values\n",
    "\n",
    "# Construct design matrix: [T, X]\n",
    "X_design = sm.add_constant(np.column_stack([T, X_covariates]))\n",
    "\n",
    "# Run logistic regression\n",
    "model = sm.Logit(Y, X_design)\n",
    "result = model.fit()\n",
    "print(result.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdcca3bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors = ['latent_medal_1', 'latent_medal_2', 'latent_medal_3', 'latent_medal_4', 'latent_medal_5', 'rating', 'Number of Years Served']\n",
    "X_constant = sm.add_constant(data_combined[predictors].astype(float))\n",
    "y = data_combined['rank_code']\n",
    "\n",
    "logit = sm.Logit(y, X_constant)\n",
    "result = logit.fit(disp=False)\n",
    "\n",
    "result.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d9b38f",
   "metadata": {},
   "outputs": [],
   "source": [
    "marginal = result.get_margeff()\n",
    "print(marginal.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb6cb2f4",
   "metadata": {},
   "source": [
    "### Nineth, let's consider the Supported Vector Machine method in the process with medal columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dbc7f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors = ['Number of Years Served', 'rating'] + medal_columns\n",
    "target_col = 'rank_code'\n",
    "\n",
    "X = data[predictors].astype(float)\n",
    "y = data[target_col].astype(int)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "linear_svm = SVC(kernel='linear', C=1)\n",
    "linear_svm.fit(X_train_scaled, y_train)\n",
    "y_pred_linear = linear_svm.predict(X_test_scaled)\n",
    "print(\"🔹 Linear SVM Accuracy:\", accuracy_score(y_test, y_pred_linear))\n",
    "print(classification_report(y_test, y_pred_linear))\n",
    "\n",
    "rbf_svm = SVC(kernel='rbf', C=1, gamma='scale')\n",
    "rbf_svm.fit(X_train_scaled, y_train)\n",
    "y_pred_rbf = rbf_svm.predict(X_test_scaled)\n",
    "print(\"🔹 RBF SVM Accuracy:\", accuracy_score(y_test, y_pred_rbf))\n",
    "print(classification_report(y_test, y_pred_rbf))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7728996a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# No rating involved\n",
    "predictors = ['Number of Years Served'] + medal_columns\n",
    "target_col = 'rank_code'\n",
    "\n",
    "X = data[predictors].astype(float)\n",
    "y = data[target_col].astype(int)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "linear_svm = SVC(kernel='linear', C=1)\n",
    "linear_svm.fit(X_train_scaled, y_train)\n",
    "y_pred_linear = linear_svm.predict(X_test_scaled)\n",
    "print(\"🔹 Linear SVM Accuracy:\", accuracy_score(y_test, y_pred_linear))\n",
    "print(classification_report(y_test, y_pred_linear))\n",
    "\n",
    "rbf_svm = SVC(kernel='rbf', C=1, gamma='scale')\n",
    "rbf_svm.fit(X_train_scaled, y_train)\n",
    "y_pred_rbf = rbf_svm.predict(X_test_scaled)\n",
    "print(\"🔹 RBF SVM Accuracy:\", accuracy_score(y_test, y_pred_rbf))\n",
    "print(classification_report(y_test, y_pred_rbf))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
